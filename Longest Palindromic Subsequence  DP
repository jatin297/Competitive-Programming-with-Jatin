Problem -> Given a sequence, find the length of the longest palindromic subsequence in it

Solution:

#include <iostream>
#include<math.h>
#include<vector>
#define ll  long long int
using namespace std;
int main()
{
    string s = "GEEGHIIIIIIII";
    int n = s.length();
    int dp[n+1][n+1];
    for(int gap = 0 ; gap < n ; gap++) {
        for (int i = 0,j=gap;j<n; i++,j++) {
            if(gap==0){
                dp[i][j] = 1;
            }
            else if(gap==1){
                if(s[i] == s[j]) {
                    dp[i][j] = 2;
                }
                else dp[i][j] = 1;
            }
            else {
                if(s[i]==s[j]) {
                    dp[i][j] = dp[i+1][j-1] + 2;
                    
                }
                else dp[i][j] = max(dp[i][j-1],dp[i+1][j]);
            }
            
        }
    }
    cout<<dp[0][n-1];
    return 0;
}
